{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9faa7d31",
   "metadata": {},
   "source": [
    "### General Setup\n",
    "\n",
    "**NOTE:** It is expected that the Notebooks are run **inside VS Code** as it allows the pathing for `task_configs` to work. If it is run outside a VS Code instance, please adjust the following line:\n",
    "\n",
    "```py\n",
    "notebook_name = \"/\".join(\n",
    "    IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[-5:]\n",
    ")\n",
    "```\n",
    "\n",
    "The cell down below has the following configuration attributes, which might need adjustment depending on changes of the experimental design\n",
    "\n",
    "- `metrics`: Inside this dictionary the keys represent the actual names of the metric, as they are displayed on `comet`, while the values are simply just given the according type that will be fetched from online.\n",
    "  \n",
    "- `parameters`: The parameters describe general experimental setup information, which were passed as arguments upon execution\n",
    "  \n",
    "- `task_names`: The task names represent the data sets upon which the Outlier Detection Strategies were trained on\n",
    "  \n",
    "- `task_configs`: The task configs represent the path to the configuration files of the `task names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a072bf8989680c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T11:54:28.203914300Z",
     "start_time": "2024-02-21T11:54:28.153936800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import comet_ml as comet\n",
    "import IPython\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Any, DefaultDict, Optional\n",
    "from collections.abc import Callable\n",
    "import numpy as np\n",
    "import textwrap\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "API = comet.API()\n",
    "\n",
    "metrics = {\n",
    "    \"AutoFilter_Chen_Like_HTL Count\": float,\n",
    "    \"AutoFilter_Chen_Like_avg_duration\": float,\n",
    "    \"AutoFilter_Chen_Like_medF1 (No HTL)\": float,\n",
    "    \"AutoFilter_Chen_Like_medF1 (With HTL)\": float,\n",
    "    \"AutoFilter_Chen_Like_avgF1 (random replacement)\": float,\n",
    "    \"AutoFilter_Chen_Like_avgF1 (No HTL)\": float,\n",
    "    \"AutoFilter_Chen_Like_avgF1 (With HTL)\": float,\n",
    "    \"AutoFilter_Chen_Like_medF1 (random replacement)\": float,\n",
    "    \"HDBScanFilter_HTL Count\": float,\n",
    "    \"HDBScanFilter_avg_duration\": float,\n",
    "    \"HDBScanFilter_medF1 (No HTL)\": float,\n",
    "    \"HDBScanFilter_medF1 (With HTL)\": float,\n",
    "    \"HDBScanFilter_medF1 (random replacement)\": float,\n",
    "    \"HDBScanFilter_avgF1 (No HTL)\": float,\n",
    "    \"HDBScanFilter_avgF1 (With HTL)\": float,\n",
    "    \"HDBScanFilter_avgF1 (random replacement)\": float,\n",
    "    \"IsolationForestFilter_HTL Count\": float,\n",
    "    \"IsolationForestFilter_avg_duration\": float,\n",
    "    \"IsolationForestFilter_avgF1 (No HTL)\": float,\n",
    "    \"IsolationForestFilter_avgF1 (With HTL)\": float,\n",
    "    \"IsolationForestFilter_avgF1 (random replacement)\": float,\n",
    "    \"IsolationForestFilter_medF1 (No HTL)\": float,\n",
    "    \"IsolationForestFilter_medF1 (With HTL)\": float,\n",
    "    \"IsolationForestFilter_medF1 (random replacement)\": float,\n",
    "    \"LocalOutlierFactorFilter_HTL Count\": float,\n",
    "    \"LocalOutlierFactorFilter_avg_duration\": float,\n",
    "    \"LocalOutlierFactorFilter_avgF1 (No HTL)\": float,\n",
    "    \"LocalOutlierFactorFilter_avgF1 (With HTL)\": float,\n",
    "    \"LocalOutlierFactorFilter_avgF1 (random replacement)\": float,\n",
    "    \"LocalOutlierFactorFilter_medF1 (No HTL)\": float,\n",
    "    \"LocalOutlierFactorFilter_medF1 (With HTL)\": float,\n",
    "    \"LocalOutlierFactorFilter_medF1 (random replacement)\": float,\n",
    "    \"LoserFilter_Plain_HTL Count\": float,\n",
    "    \"LoserFilter_Plain_avg_duration\": float,\n",
    "    \"LoserFilter_Plain_avgF1 (No HTL)\": float,\n",
    "    \"LoserFilter_Plain_avgF1 (With HTL)\": float,\n",
    "    \"LoserFilter_Plain_avgF1 (random replacement)\": float,\n",
    "    \"LoserFilter_Plain_medF1 (No HTL)\": float,\n",
    "    \"LoserFilter_Plain_medF1 (With HTL)\": float,\n",
    "    \"LoserFilter_Plain_medF1 (random replacement)\": float,\n",
    "    \"SingleStepEntropy_SimplePseudo_HTL Count\": float,\n",
    "    \"SingleStepEntropy_SimplePseudo_avg_duration\": float,\n",
    "    \"SingleStepEntropy_SimplePseudo_avgF1 (No HTL)\": float,\n",
    "    \"SingleStepEntropy_SimplePseudo_avgF1 (With HTL)\": float,\n",
    "    \"SingleStepEntropy_SimplePseudo_avgF1 (random replacement)\": float,\n",
    "    \"SingleStepEntropy_SimplePseudo_medF1 (No HTL)\": float,\n",
    "    \"SingleStepEntropy_SimplePseudo_medF1 (With HTL)\": float,\n",
    "    \"SingleStepEntropy_SimplePseudo_medF1 (random replacement)\": float,\n",
    "}\n",
    "parameters = {\n",
    "    \"strategy_name\": str,\n",
    "    \"filter_strategy_name\": str,\n",
    "    \"seed\": int,\n",
    "    \"task\": str,\n",
    "}\n",
    "\n",
    "task_names = [\n",
    "    \"ag-news\",\n",
    "    \"dbpedia\",\n",
    "    \"fnc1\",\n",
    "    \"imdb\",\n",
    "    \"qnli\",\n",
    "    \"rotten-tomatoes\",\n",
    "    \"sst2\",\n",
    "    \"trec\",\n",
    "    \"wiki-talk\",\n",
    "]\n",
    "\n",
    "version = \"x\"\n",
    "task_names = [version + t for t in task_names]\n",
    "\n",
    "# This gets the location of the Notebook, needs VSCode to be executed correctly\n",
    "notebook_name = \"/\".join(\n",
    "    IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[-5:]\n",
    ")\n",
    "\n",
    "BASE_PATH = Path(notebook_name).parent\n",
    "CONFIGS_PATH = BASE_PATH.parent / \"Configs\" / \"Tasks\"\n",
    "\n",
    "task_configs = {\n",
    "    \"xAG News\": CONFIGS_PATH / \"ag_news.json\",\n",
    "    \"xDBPedia\": CONFIGS_PATH / \"dbpedia.json\",\n",
    "    \"xFNC1\": CONFIGS_PATH / \"fnc_one.json\",\n",
    "    \"xIMDB\": CONFIGS_PATH / \"imdb.json\",\n",
    "    \"xQNLI\": CONFIGS_PATH / \"qnli.json\",\n",
    "    \"xRotten Tomatoes\": CONFIGS_PATH / \"rotten_tomatoes.json\",\n",
    "    \"xSST2\": CONFIGS_PATH / \"sst2.json\",\n",
    "    \"xTREC\": CONFIGS_PATH / \"trec.json\",\n",
    "    \"xWiki Talk\": CONFIGS_PATH / \"wiki_talk.json\",\n",
    "}\n",
    "\n",
    "seed_count = 20  # How many different seeds do we expect?\n",
    "\n",
    "COMET_WORKSPACE = \"final-experiment-all-filters\"\n",
    "filter_names = [\n",
    "    \"HDBScanFilter LocalOutlierFactorFilter IsolationForestFilter SimpleDSM SemanticAE SimpleSS\"\n",
    "]\n",
    "\n",
    "filter_names_final_experiment = [\n",
    "    \"HDBScanFilter\", \"LocalOutlierFactorFilter\", \"IsolationForestFilter\", \"SimpleDSM\", \"SemanticAE\", \"SimpleSS\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "700c8726a3f36ad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T11:54:29.916779600Z",
     "start_time": "2024-02-21T11:54:29.886500800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_used_metrics(experiment_metrics: List[Dict[str, Any]]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Extract a list of unique metrics from the given experiment metrics that are also present in the `metrics` list.\n",
    "\n",
    "    Args:\n",
    "        experiment_metrics (List[Dict[str, Any]]): A list of dictionaries where each dictionary\n",
    "            represents a metric with various attributes, including \"metricName\".\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of unique metric dictionaries where \"metricName\" exists in the global `metrics` list.\n",
    "    \"\"\"\n",
    "    metrics_used: List[Dict] = []\n",
    "    for metric in experiment_metrics:\n",
    "        if metric[\"metricName\"] in metrics:\n",
    "            metrics_used.append(metric)\n",
    "    return metrics_used\n",
    "\n",
    "\n",
    "def extract_paremeter_value(\n",
    "    parameters_used: List[Dict[str, Any]], parameter_name: str\n",
    ") -> str | float:\n",
    "    \"\"\"\n",
    "    Extracts the current value of a specified parameter from a list of parameters.\n",
    "\n",
    "    Args:\n",
    "        parameters_used (List[Dict[str, Any]]): A list of dictionaries containing parameter information.\n",
    "        parameter_name (str): The name of the parameter to extract.\n",
    "\n",
    "    Returns:\n",
    "        str | float: The current value of the specified parameter.\n",
    "    \"\"\"\n",
    "    parameters_dict = [\n",
    "        entry for entry in parameters_used if entry.get(\"name\") == parameter_name\n",
    "    ]\n",
    "    return parameters_dict[0][\"valueCurrent\"]\n",
    "\n",
    "\n",
    "def load_experiment_data(\n",
    "    experiment: comet.APIExperiment, final_experiment: Optional[bool] = False, filter_strategy: Optional[str] = \"\"\n",
    ") -> DefaultDict[str, DefaultDict[str, DefaultDict[str, Dict[str, Any]]]]:\n",
    "    \"\"\"\n",
    "    Loads and organizes experiment data, including metrics, parameters, and assets.\n",
    "\n",
    "    Args:\n",
    "        experiment (comet.APIExperiment): A Comet APIExperiment object containing experiment data.\n",
    "\n",
    "    Returns:\n",
    "        DefaultDict[str, DefaultDict[str, DefaultDict[str, Dict[str, Any]]]]: A nested dictionary with tasks, seeds, and experiment data.\n",
    "    \"\"\"\n",
    "\n",
    "    experiment_parameters = experiment.get_parameters_summary()\n",
    "    task = extract_paremeter_value(experiment_parameters, \"task\")\n",
    "    seed = extract_paremeter_value(experiment_parameters, \"seed\")\n",
    "\n",
    "    if final_experiment:\n",
    "        filter_strategy = extract_paremeter_value(experiment_parameters, \"filter_strategy_name\")\n",
    "\n",
    "    kwargs = {\n",
    "        \"task\" : task,\n",
    "        \"seed\" : seed,\n",
    "        \"filter_strategy\" : filter_strategy\n",
    "    }\n",
    "\n",
    "    download_assets(experiment, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def download_assets(experiment:comet.APIExperiment, task: str, seed: str, filter_strategy: Optional[str] = \"\") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Downloads and saves the assets of an experiment, filtering out unnecessary files.\n",
    "\n",
    "    Args:\n",
    "        experiment (comet.APIExperiment): A Comet APIExperiment object containing the experiment data.\n",
    "        task (str): The task name associated with the experiment.\n",
    "        seed (str): The seed value associated with the experiment.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, np.ndarray]: A dictionary of downloaded assets, loaded as NumPy arrays.\n",
    "    \"\"\"\n",
    "    assets = experiment.get_asset_list()\n",
    "    filtered_assets = [\n",
    "        asset\n",
    "        for asset in assets\n",
    "        if \"durations\" not in asset[\"fileName\"]\n",
    "        and not asset[\"fileName\"].endswith(\".py\")\n",
    "    ]\n",
    "\n",
    "    asset_ids = []\n",
    "    for asset in filtered_assets:\n",
    "        asset_ids.append((asset[\"fileName\"], asset[\"assetId\"]))\n",
    "\n",
    "    for file_name, idx in asset_ids:\n",
    "        asset_data = experiment.get_asset(idx)\n",
    "        if filter_strategy:\n",
    "            asset_path = Path(f\"./cache/assets/{COMET_WORKSPACE}/{task}/{seed}/{filter_strategy}_{file_name}\")\n",
    "        else:\n",
    "            asset_path = Path(f\"./cache/assets/{COMET_WORKSPACE}/{task}/{seed}/{file_name}\")\n",
    "        asset_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(asset_path, \"wb\") as f:\n",
    "            f.write(asset_data)\n",
    "\n",
    "\n",
    "def download_workspace_data(task_name: str, final_exp: Optional[bool] = False) -> None:\n",
    "    \"\"\"\n",
    "    Loads experiment data for a specific project from the Comet workspace.\n",
    "\n",
    "    Args:\n",
    "        project_name (str): The name of the project to load data from.\n",
    "    \"\"\"\n",
    "    experiments = API.get(workspace=COMET_WORKSPACE, project_name=task_name)\n",
    "    for exp in experiments:\n",
    "        load_experiment_data(exp, final_experiment=final_exp)\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    for task_name in task_names:\n",
    "        download_workspace_data(task_name)\n",
    "\n",
    "def main_final_exp() -> None:\n",
    "    for task_name in task_names:\n",
    "        download_workspace_data(task_name, final_exp=True)\n",
    "\n",
    "\n",
    "# main()\n",
    "main_final_exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_integer_directory(dir_path: Path) -> bool:\n",
    "    \"\"\"Check if the directory name is an integer.\"\"\"\n",
    "    return dir_path.name.isdigit()\n",
    "\n",
    "def collect_asset_paths(ASSET_PATHS: Optional[Path] = Path(\"cache\", \"assets\", COMET_WORKSPACE)) -> DefaultDict[str, List]:\n",
    "    TASK_ASSET_MAP = defaultdict(list)\n",
    "    for dir_path in ASSET_PATHS.glob('**/*'):\n",
    "        if dir_path.is_dir() and is_integer_directory(dir_path):\n",
    "            task_name = dir_path.parent.name\n",
    "            if task_name != COMET_WORKSPACE:\n",
    "                TASK_ASSET_MAP[task_name].append(dir_path)\n",
    "\n",
    "    return TASK_ASSET_MAP\n",
    "\n",
    "def check_for_every_strategy(ASSET_PATHS: Optional[Path] = Path(\"cache\", \"assets\", COMET_WORKSPACE)):\n",
    "    strategies_map = defaultdict(lambda: defaultdict(list))\n",
    "    for path in ASSET_PATHS.glob('**/*'):\n",
    "        if path.name.endswith(\"_f1s.npy\"):\n",
    "            strategy_name = path.name.replace(\"_f1s.npy\", \"\")\n",
    "            seed_name = path.parent.name\n",
    "            task_name = path.parent.parent.name\n",
    "            if task_name != COMET_WORKSPACE:\n",
    "                strategies_map[task_name][seed_name].append(strategy_name)\n",
    "\n",
    "    return strategies_map\n",
    "\n",
    "def find_missing_seeds_count(task_asset_map: DefaultDict[str, List], final_experiment: Optional[bool] = False) -> DefaultDict[str, List]:\n",
    "    seed_map = defaultdict(list)\n",
    "    for task, asset_paths in task_asset_map.items():\n",
    "        seeds = [int(path.name) for path in asset_paths]\n",
    "        missing_seeds: List | None = np.setdiff1d(np.arange(42, 42 + seed_count), seeds).tolist()\n",
    "        seed_map[task] = missing_seeds\n",
    "\n",
    "    skipped_tasks = np.setdiff1d(list(task_configs.keys()), list(task_asset_map.keys())).tolist()\n",
    "    for task in skipped_tasks:\n",
    "        seed_map[task] = np.arange(42, 42 + seed_count).tolist()\n",
    "\n",
    "    if final_experiment:\n",
    "        missed_strategies = defaultdict(lambda: defaultdict(list))\n",
    "        filter_strategies_length = len(filter_names_final_experiment)\n",
    "        strategies_map = check_for_every_strategy()\n",
    "        for task, seed_dict in strategies_map.items():\n",
    "            for seed, strategies_list in seed_dict.items():\n",
    "                if len(strategies_list) != filter_strategies_length:\n",
    "                    missing_strategies = np.setdiff1d(filter_names_final_experiment, strategies_list)\n",
    "                    missed_strategies[task][seed] = missing_strategies\n",
    "\n",
    "    if missed_strategies:\n",
    "        print(\"The following Strategies were skipped during experiments: \")\n",
    "        for task, seed_dict2 in missed_strategies.items():\n",
    "            for seed, strategies_list in seed_dict2.items():\n",
    "                print(f\"{task} - {seed}: {strategies_list}\")\n",
    "\n",
    "    return seed_map\n",
    "\n",
    "\n",
    "TASK_ASSET_MAP = collect_asset_paths()\n",
    "missing_seeds = find_missing_seeds_count(task_asset_map=TASK_ASSET_MAP, final_experiment=True)\n",
    "print(\"\\nMissed seeds during experiments\")\n",
    "missing_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e300922",
   "metadata": {},
   "source": [
    "### (Optional) Find Missing Experimental Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33c0bc58138c54a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T12:53:02.254155500Z",
     "start_time": "2024-02-21T11:54:32.912064200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collected_data: List[pd.DataFrame] = []\n",
    "\n",
    "def get_task_config(task: Path) -> Path:\n",
    "    \"\"\"Transform in the input `task` into a Path object.\n",
    "\n",
    "    Args:\n",
    "        task (Path): A Path object, containing the full Path to the config\n",
    "\n",
    "    Returns:\n",
    "        Path: A relative Path based on the `task_configs` dict based on the relative Path: `Configs/Task/`\n",
    "    \"\"\"\n",
    "    return task.relative_to(task.parents[2])\n",
    "\n",
    "\n",
    "def generate_missing_seeds_df(missing_seeds: DefaultDict[str, List]) -> None:\n",
    "    for task_name, missed_seeds in missing_seeds.items():\n",
    "        task = get_task_config(task_configs[task_name])\n",
    "        if missed_seeds:\n",
    "            df = pd.DataFrame(\n",
    "            [\n",
    "                {\"seed\": seed, \"filter\": filter_names[0], \"task\": task, \"workspace\": COMET_WORKSPACE}\n",
    "                for seed in missed_seeds\n",
    "            ]\n",
    "            )\n",
    "            collected_data.append(df)\n",
    "\n",
    "    if collected_data:\n",
    "        missing_experiments = pd.concat(collected_data)\n",
    "        missing_experiments = missing_experiments[\n",
    "            missing_experiments[\"filter\"].isin(filter_names)\n",
    "        ]\n",
    "        missing_experiments.to_csv(f\"missing_std_experiments_{COMET_WORKSPACE}.csv\", mode=\"w+\")\n",
    "        missing_experiments\n",
    "\n",
    "\n",
    "def main():\n",
    "    TASK_ASSET_MAP = collect_asset_paths()\n",
    "    missing_seeds = find_missing_seeds_count(task_asset_map=TASK_ASSET_MAP, final_experiment=True)\n",
    "    generate_missing_seeds_df(missing_seeds)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c444d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intervals(seeds: list[int]) -> List[List[int]]:\n",
    "    \"\"\"Finds the largest contiguous intervals in a list of integers. It groups consecutive integers into a sublist.\n",
    "\n",
    "    Args:\n",
    "        seeds (list[int]): A list of integers to find (all and) the largest intervals from.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the provided list for `seeds` is empty.\n",
    "\n",
    "    Returns:\n",
    "        List[List[int]]: A list of lists, where each inner list contains a contiguous interval of integers.\n",
    "\n",
    "    Examples:\n",
    "        >>> find_intervals([1, 2, 3, 5, 6, 7, 9])\n",
    "        [[1, 2, 3], [5, 6, 7], [9]]\n",
    "\n",
    "        >>> find_intervals([10, 11, 13, 14, 15, 16])\n",
    "        [[10, 11], [13, 14, 15, 16]]\n",
    "    \"\"\"\n",
    "    if not seeds:\n",
    "        raise ValueError(\n",
    "            f\"The provided list for `seeds` ({seeds}) has: {len(seeds)} elements!\"\n",
    "        )\n",
    "    intervals = []\n",
    "\n",
    "    sub_interval = [seeds[0]]\n",
    "\n",
    "    for index in range(1, len(seeds)):\n",
    "        if seeds[index] == seeds[index - 1] + 1:\n",
    "            sub_interval.append(seeds[index])\n",
    "        else:\n",
    "            # Add the completed interval to the result and start a new interval right after\n",
    "            intervals.append(sub_interval)\n",
    "            sub_interval = [seeds[index]]\n",
    "\n",
    "    # Append the last interval, as it only gets added within the iteration, so the last one would be missing\n",
    "    intervals.append(sub_interval)\n",
    "    return intervals\n",
    "\n",
    "\n",
    "def generate_task_scripts(\n",
    "    intervals: List[List[int]], task_config: str, workspace: str\n",
    ") -> None:\n",
    "    for index, interval in enumerate(intervals):\n",
    "        start = interval[0] - 42\n",
    "        end = interval[-1] - 42\n",
    "\n",
    "        # A task has the structure \"Configs/Tasks/<task_name>.json\" -> we want the <task_name>.json, then remove the \".json\"\n",
    "        task_name_cleaned = task_config.split(\"/\")[-1].split(\".\")[0]\n",
    "        # Common SLURM script header\n",
    "        slurm_header = textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            #!/bin/bash\n",
    "            #SBATCH --nodes=1              # request 1 node\n",
    "            #SBATCH --cpus-per-task=6      # use 6 threads per task\n",
    "            #SBATCH --gres=gpu:1           # use 1 GPU per node (i.e. use one GPU per task)\n",
    "            #SBATCH --time=100:00:00       # run for 100 hours\n",
    "            #SBATCH --mem=10G\n",
    "            #SBATCH --account=p_ml_il\n",
    "            #SBATCH --job-name={workspace}-{task_config}\n",
    "            #SBATCH --output=./slurm-runs/{workspace}/{workspace}-{task_name_cleaned}-%a-%A-%j.out\n",
    "            #SBATCH --exclude=i8003,i8007,i8008,i8009,i8011,i8014,i8021,i8023,i8027,i8032\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "        # Array setup if start and end differ\n",
    "        array_directive = f\"#SBATCH --array={start}-{end}\\n\" if start != end else \"\"\n",
    "\n",
    "        # Command to calculate random seed\n",
    "        seed_command = (\n",
    "            f\"random_seed=$((42 + ${{SLURM_ARRAY_TASK_ID}}))\"\n",
    "            if start != end\n",
    "            else f\"random_seed={interval[0]}\"\n",
    "        )\n",
    "\n",
    "        # Common SLURM script body\n",
    "        slurm_body = textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            {array_directive}\n",
    "            module --force purge\n",
    "            module load release/23.04 GCC/11.3.0 Python/3.10.4\n",
    "            source /data/horse/ws/toma076c-outlier-detection/venv/bin/activate\n",
    "\n",
    "            nvidia-smi\n",
    "            hostname\n",
    "\n",
    "            # Calculate the random seed within the SLURM script\n",
    "            {seed_command}\n",
    "\n",
    "            echo \"Seed: ${{random_seed}}\"\n",
    "\n",
    "            srun python3 main.py \\\n",
    "                --task_config ./{task_config} \\\n",
    "                --experiment_config ./Configs/standard.json \\\n",
    "                --filter_strategy_name HDBScanFilter LocalOutlierFactorFilter IsolationForestFilter SimpleDSM SemanticAE SimpleSS \\\n",
    "                --comet_api_key {API.api_key} \\\n",
    "                --comet_workspace {workspace} \\\n",
    "                --random_seed ${{random_seed}}\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "        # Write the complete SLURM script\n",
    "        with open(f\"{workspace}-{task_name_cleaned}-{index}.sh\", \"w+\") as rsh:\n",
    "            rsh.write(slurm_header + slurm_body)\n",
    "\n",
    "\n",
    "def collect_missing_experiment_seeds(missing_experiments: pd.DataFrame) -> None:\n",
    "    unique_tasks = missing_experiments[\"task\"].unique()\n",
    "    for task in unique_tasks:\n",
    "        # We only care for all the rows that match the current task, so we create a subset of the df\n",
    "        task_df = missing_experiments.loc[missing_experiments[\"task\"] == task]\n",
    "        seeds = sorted(\n",
    "            task_df[\"seed\"].values\n",
    "        )  # Sort the seeds, to assure the biggest intervals are found\n",
    "        workspace = task_df[\"workspace\"].iloc[0]\n",
    "        task_intervals = find_intervals(seeds)\n",
    "        generate_task_scripts(intervals=task_intervals, task_config=task, workspace=workspace)\n",
    "\n",
    "\n",
    "missing_experiments = pd.read_csv(f\"missing_std_experiments_{COMET_WORKSPACE}.csv\")\n",
    "x = collect_missing_experiment_seeds(missing_experiments=missing_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd640506",
   "metadata": {},
   "source": [
    "### Plot Filter vs No Filter & Filter vs Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ed05b234aadca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T14:30:05.879416900Z",
     "start_time": "2024-02-01T14:30:04.230197800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_names_clean = {\n",
    "    \"LoserFilter_Plain\": \"Simple DSM\",\n",
    "    \"AutoFilter_Chen_Like\": \"Semantic AE\",\n",
    "    \"SingleStepEntropy_SimplePseudo\": \"Simple SS\",\n",
    "    \"HDBScanFilter\": \"HDBScan\",\n",
    "    \"IsolationForestFilter\": \"IsolationForest\",\n",
    "    \"LocalOutlierFactorFilter\": \"LocalOutlierFactor\",\n",
    "}\n",
    "\n",
    "def load_asset_data(workspace_data: DefaultDict[str, List[Path]]) -> Dict[str, pd.DataFrame]:\n",
    "\n",
    "    asset_data = {}\n",
    "    for task_name, asset_dirs in workspace_data.items():\n",
    "        collected_assets = []\n",
    "        for asset_dir in asset_dirs:\n",
    "            asset_paths = asset_dir.glob(\"*\")\n",
    "            collected_dfs = []\n",
    "            for asset_path in asset_paths:\n",
    "                data = np.load(asset_path)\n",
    "                if data.size == 0:\n",
    "                    print(f\"{asset_path} is empty\")\n",
    "                df = pd.DataFrame(data={asset_path.name[:-4]: [data]})\n",
    "                if df.empty:\n",
    "                    print(f\"Careful! For '{task_name}', the '{asset_path}' file is empty.\")\n",
    "                else:\n",
    "                    collected_dfs.append(df)\n",
    "\n",
    "            collected_assets.append(pd.concat(collected_dfs, axis=1))\n",
    "\n",
    "        asset_data[task_name] = pd.concat(collected_assets, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "    return asset_data\n",
    "\n",
    "\n",
    "def clean_up_asset_name(asset_name: str) -> str:\n",
    "    \"\"\"\n",
    "    This function removes the `_no_htl` and `_random` extension from the asset.\n",
    "    For example: `AutoFilter_Chen_Like_no_htl` would be transformed into `AutoFilter_Chen_Like`.\n",
    "    Args:\n",
    "        asset_name (str): The name of the asset to be (potentially) changed, as some do not have the aforementioned suffixes\n",
    "\n",
    "    Returns:\n",
    "        str: The updated asset_name\n",
    "    \"\"\"\n",
    "    if asset_name.endswith(\"_no_htl\") or asset_name.endswith(\"_random\"):\n",
    "        asset_name = asset_name[:-7]\n",
    "\n",
    "    cleaned_asset = filter_names_clean[asset_name]\n",
    "    return cleaned_asset\n",
    "\n",
    "\n",
    "def calculate_averages(\n",
    "    asset_data: Dict[str, Dict[str, pd.DataFrame]]\n",
    ") -> DefaultDict[str, DefaultDict[str, np.float64]]:\n",
    "\n",
    "    summarised_data = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    for task_name, asset_df in asset_data.items():\n",
    "        for asset_name in asset_df.columns:\n",
    "            arrays_for_col = asset_df[asset_name].values\n",
    "            flattened_array = np.concatenate(arrays_for_col)\n",
    "            if flattened_array.size == 0:\n",
    "                print(f\"Empty array found for: {asset_name} in {task_name}\")\n",
    "            else:\n",
    "                mean = flattened_array.mean()\n",
    "                summarised_data[task_name][asset_name] = mean\n",
    "\n",
    "    return summarised_data\n",
    "\n",
    "\n",
    "def prepare_data():\n",
    "    workspace_data = collect_asset_paths()\n",
    "    asset_data = load_asset_data(workspace_data=workspace_data)\n",
    "    summarised_data = calculate_averages(asset_data)\n",
    "    return summarised_data\n",
    "\n",
    "def transform_into_percentual_difference(asset_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in asset_df.columns:\n",
    "        if col != \"HTL\":\n",
    "            asset_df[col] = (asset_df[col] - asset_df[\"HTL\"]).mul(100)\n",
    "\n",
    "    return asset_df\n",
    "\n",
    "\n",
    "def filter_no_htl(asset_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    This is a helper function for the `create_comparison_df()` function. It is used to compare `No HTL` with `HTL`, so the filter condition looks for assets that contain `_no_htl` in their name.\n",
    "\n",
    "    Args:\n",
    "        asset_name (str): The asset to check for.\n",
    "\n",
    "    Returns:\n",
    "        bool: Returns `True` if the asset ends with `_no_htl`, else defaults to `False`.\n",
    "    \"\"\"\n",
    "    return asset_name.endswith(\"_no_htl\")\n",
    "\n",
    "\n",
    "def filter_random(asset_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    This is a helper function for the `create_comparison_df()` function. It is used to compare `Random (Filled Up)` with `HTL`, so the filter condition looks for assets that contain `_random` in their name.\n",
    "\n",
    "    Args:\n",
    "        asset_name (str): The asset to check for.\n",
    "\n",
    "    Returns:\n",
    "        bool: Returns `True` if the asset ends with `_random`, else defaults to `False`.\n",
    "    \"\"\"\n",
    "    return asset_name.endswith(\"_random\")\n",
    "\n",
    "\n",
    "def create_comparison_df(\n",
    "    data: DefaultDict[str, DefaultDict[str, np.float64]],\n",
    "    filter_condition: Callable[[str], bool],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a comparison DataFrame by filtering asset names based on a given condition\n",
    "    and transforming them into percentual differences.\n",
    "\n",
    "    This function processes a nested dictionary structure where each task contains a dictionary\n",
    "    of assets and their corresponding values. For each task, it filters the asset names according\n",
    "    to the provided `filter_condition` function, cleans up asset names as needed, and collects\n",
    "    assets ending with \"HTL\". The resulting DataFrame for each task is transformed into percentual\n",
    "    differences and concatenated into a final DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data (DefaultDict[str, DefaultDict[str, np.float64]]):\n",
    "            A nested dictionary where the outer key is the task name, the inner dictionary contains\n",
    "            asset names as keys and their values as floats.\n",
    "\n",
    "        filter_condition (Callable[[str], bool]):\n",
    "            A function that takes an asset name (string) and returns a boolean indicating whether\n",
    "            the asset should be included in the comparison. The function is responsible for determining\n",
    "            if an asset meets the filtering criteria.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame:\n",
    "            A concatenated DataFrame containing percentual differences for the filtered assets\n",
    "            across all tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    dfs: list[pd.DataFrame] = []\n",
    "    for task_name, asset_dict in data.items():\n",
    "        collected_assets = {}\n",
    "        for asset_name, asset_value in asset_dict.items():\n",
    "            if filter_condition(asset_name):\n",
    "                cleaned_asset = clean_up_asset_name(asset_name)\n",
    "                collected_assets[cleaned_asset] = asset_value\n",
    "            elif asset_name.endswith(\"HTL\"):\n",
    "                collected_assets[asset_name] = asset_value\n",
    "\n",
    "        asset_df = transform_into_percentual_difference(\n",
    "            asset_df=pd.DataFrame(data=collected_assets, index=[task_name])\n",
    "        )\n",
    "        dfs.append(asset_df)\n",
    "\n",
    "    merged_df = pd.concat(dfs)\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "def main():\n",
    "    summarised_data = prepare_data()\n",
    "    data_filtered = create_comparison_df(summarised_data, filter_no_htl)\n",
    "    data_unfiltered = create_comparison_df(summarised_data, filter_random)\n",
    "\n",
    "    sns.set_theme()\n",
    "    sns.xkcd_palette\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(17, 11))\n",
    "\n",
    "    sns.heatmap(\n",
    "        data=data_filtered[data_filtered.columns.difference([\"HTL\"])],                     # Overlap matrix as data\n",
    "        annot=True,                    # Annotate cells with values\n",
    "        fmt=\".2f\",                     # Format annotations to 2 decimal places\n",
    "        annot_kws={\"size\": 8},         # Font size for annotations\n",
    "        linewidths=0.5,                # Thin borders for each cell\n",
    "        linecolor='grey',              # Grey borders to define the stairwell look\n",
    "        cbar_kws={'shrink': 0.5},      # Shrink color bar for fitting\n",
    "        square=True,                    # Square cells for a structured look\n",
    "        ax=axes[0]\n",
    "    )\n",
    "    axes[0].set_title(\"Filtered vs Unfiltered\")\n",
    "\n",
    "    sns.heatmap(\n",
    "    data=data_unfiltered[data_unfiltered.columns.difference([\"HTL\"])],                     # Overlap matrix as data\n",
    "    annot=True,                    # Annotate cells with values\n",
    "    fmt=\".2f\",                     # Format annotations to 2 decimal places\n",
    "    annot_kws={\"size\": 8},         # Font size for annotations\n",
    "    linewidths=0.5,                # Thin borders for each cell\n",
    "    linecolor='grey',              # Grey borders to define the stairwell look\n",
    "    cbar_kws={'shrink': 0.5},      # Shrink color bar for fitting\n",
    "    square=True,                    # Square cells for a structured look\n",
    "    ax=axes[1]\n",
    "    )\n",
    "    axes[1].set_title(\"Random(Filled Up) vs Unfiltered\")\n",
    "\n",
    "    plt.savefig(\"./img/minimal-difference/filtered_vs_unfiltered_vs_random.pdf\", format=\"pdf\", dpi=300)\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e9525",
   "metadata": {},
   "source": [
    "### Significance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb9d191b06d81d1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5.3 Significance Test from Paper\n",
    "\n",
    "# HTL mit NO HTL Vergleich & Random mit NO HTL vergleichen <-- Random hinzufÃ¼gen (einfach assets laden)\n",
    "import deepsig\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "def load_asset_data(workspace_data: DefaultDict[str, List[Path]]) -> Dict[str, pd.DataFrame]:\n",
    "\n",
    "    asset_data = {}\n",
    "    for task_name, asset_dirs in workspace_data.items():\n",
    "        collected_assets = []\n",
    "        for asset_dir in asset_dirs:\n",
    "            asset_paths = asset_dir.glob(\"*\")\n",
    "            collected_dfs = []\n",
    "            for asset_path in asset_paths:\n",
    "                data = np.load(asset_path)\n",
    "                if data.size == 0:\n",
    "                    print(f\"{asset_path} is empty\")\n",
    "                df = pd.DataFrame(data={asset_path.name[:-4]: [data]})\n",
    "                if df.empty:\n",
    "                    print(f\"Careful! For '{task_name}', the '{asset_path}' file is empty.\")\n",
    "                else:\n",
    "                    collected_dfs.append(df)\n",
    "\n",
    "            collected_assets.append(pd.concat(collected_dfs, axis=1))\n",
    "\n",
    "        asset_data[task_name] = pd.concat(collected_assets, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "    return asset_data\n",
    "\n",
    "def collect_asset_paths(ASSET_PATHS: Optional[Path] = Path(\"cache\", \"assets\", COMET_WORKSPACE)) -> DefaultDict[str, List]:\n",
    "    TASK_ASSET_MAP = defaultdict(list)\n",
    "    for dir_path in ASSET_PATHS.glob('**/*'):\n",
    "        if dir_path.is_dir() and is_integer_directory(dir_path):\n",
    "            task_name = dir_path.parent.name\n",
    "            if task_name != COMET_WORKSPACE:\n",
    "                TASK_ASSET_MAP[task_name].append(dir_path)\n",
    "\n",
    "    return TASK_ASSET_MAP\n",
    "\n",
    "def filter_no_htl(asset_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    This is a helper function for the `create_comparison_df()` function. It is used to compare `No HTL` with `HTL`, so the filter condition looks for assets that contain `_no_htl` in their name.\n",
    "\n",
    "    Args:\n",
    "        asset_name (str): The asset to check for.\n",
    "\n",
    "    Returns:\n",
    "        bool: Returns `True` if the asset ends with `_no_htl`, else defaults to `False`.\n",
    "    \"\"\"\n",
    "    return asset_name.endswith(\"_no_htl\")\n",
    "\n",
    "\n",
    "def filter_random(asset_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    This is a helper function for the `create_comparison_df()` function. It is used to compare `Random (Filled Up)` with `HTL`, so the filter condition looks for assets that contain `_random` in their name.\n",
    "\n",
    "    Args:\n",
    "        asset_name (str): The asset to check for.\n",
    "\n",
    "    Returns:\n",
    "        bool: Returns `True` if the asset ends with `_random`, else defaults to `False`.\n",
    "    \"\"\"\n",
    "    return asset_name.endswith(\"_random\")\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='app.log',        # Log file name\n",
    "    filemode='a',              # Append mode (use 'w' for overwrite)\n",
    "    level=logging.DEBUG,       # Minimum log level to handle\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s' # Log message format\n",
    ")\n",
    "\n",
    "def helper_function(significance_test_data: Dict[str, pd.DataFrame], filter_condition: Callable[[str], bool]) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "    results = {}\n",
    "    for task_name, asset_df in significance_test_data.items():\n",
    "        collected_assets = {}\n",
    "        for col in asset_df.columns:\n",
    "            if filter_condition(col):\n",
    "                cleaned_asset = clean_up_asset_name(col)\n",
    "                flattened_array = np.concatenate(asset_df[col].values)\n",
    "                if flattened_array.size == 0:\n",
    "                    print(f\"Empty array found for: {col} in {task_name}\")\n",
    "                else:\n",
    "                    collected_assets[cleaned_asset] = flattened_array\n",
    "            elif col.endswith(\"HTL\"):\n",
    "                collected_assets[col] = np.concatenate(asset_df[col].values)\n",
    "\n",
    "        results[task_name] = collected_assets\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def prepare_significance_test_data(filter_condition: Callable[[str], bool]) -> Dict[str, pd.DataFrame]:\n",
    "    workspace_data = collect_asset_paths()\n",
    "    asset_data = load_asset_data(workspace_data=workspace_data)\n",
    "\n",
    "    return helper_function(asset_data, filter_condition)\n",
    "\n",
    "\n",
    "def signifance_test(comparison_data: Dict[str, pd.DataFrame], file_name: str):\n",
    "    results = []\n",
    "    for task_name, assets_dict in comparison_data.items():\n",
    "        task_aso = []\n",
    "        htl_data = assets_dict[\"HTL\"]\n",
    "        for filter_strategy, data in assets_dict.items():\n",
    "            if filter_strategy != \"HTL\":\n",
    "                if (len(data) != seed_count * 30) or (len(htl_data) != seed_count * 30):\n",
    "                    logging.error(f\"Error! In {task_name} the filterstrategy '{filter_strategy}' has '{len(data)}' Data, and '{len(htl_data)}' HTL Data but expected were: '{seed_count * 30}'\")\n",
    "\n",
    "\n",
    "                better = deepsig.aso(data, htl_data, num_bootstrap_iterations=10000, num_jobs=8, seed=42)\n",
    "                task_aso.append(better)\n",
    "\n",
    "        assets_dict.pop(\"HTL\", None)\n",
    "        results.append(pd.DataFrame(data=[task_aso], columns=assets_dict.keys(), index=[f\"{task_name}_{file_name}\"]))\n",
    "\n",
    "    df = pd.concat(results)\n",
    "    df.to_csv(f\"./img/minimal-difference/{COMET_WORKSPACE}_{file_name}.csv\")\n",
    "\n",
    "def no_htl_vs_htl():\n",
    "    return prepare_significance_test_data(filter_no_htl)\n",
    "\n",
    "def random_vs_htl():\n",
    "    return prepare_significance_test_data(filter_random)\n",
    "\n",
    "def main():\n",
    "    signifance_test(no_htl_vs_htl(), \"no_htl_better\")\n",
    "    signifance_test(random_vs_htl(), \"random_better\")\n",
    "    logging.debug(\"Done with random_better\")\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f53c19f",
   "metadata": {},
   "source": [
    "### Visualize Significance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f55626",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "sns.xkcd_palette\n",
    "fig, axes = plt.subplots(1, 2, figsize=(17, 11))\n",
    "\n",
    "no_htl = pd.read_csv(\"./img/minimal-difference/outlier-detection_no_htl_better.csv\", index_col=0)\n",
    "no_htl.index = [updated_index.split(\"_\")[0] for updated_index in list(no_htl.index)]\n",
    "random_better = pd.read_csv(\"./img/minimal-difference/outlier-detection_random_better.csv\", index_col=0)\n",
    "random_better.index = [updated_index.split(\"_\")[0] for updated_index in list(random_better.index)]\n",
    "\n",
    "sns.heatmap(\n",
    "    data=no_htl,\n",
    "    annot=True,                    # Annotate cells with values\n",
    "    fmt=\".2f\",                     # Format annotations to 2 decimal places\n",
    "    annot_kws={\"size\": 8},         # Font size for annotations\n",
    "    linewidths=0.5,                # Thin borders for each cell\n",
    "    linecolor='grey',              # Grey borders to define the stairwell look\n",
    "    cbar_kws={'shrink': 0.5},      # Shrink color bar for fitting\n",
    "    square=True,                   # Square cells for a structured look\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Significance Test No HTL vs HTL\")\n",
    "# \"Here no HTL was set A and HTL was set B. Meaning that if the significance test < 0.25 then no HTL was statistically better than HTL.\",\n",
    "\n",
    "sns.heatmap(\n",
    "data=random_better,\n",
    "annot=True,                    # Annotate cells with values\n",
    "fmt=\".2f\",                     # Format annotations to 2 decimal places\n",
    "annot_kws={\"size\": 8},         # Font size for annotations\n",
    "linewidths=0.5,                # Thin borders for each cell\n",
    "linecolor='grey',              # Grey borders to define the stairwell look\n",
    "cbar_kws={'shrink': 0.5},      # Shrink color bar for fitting\n",
    "square=True,                   # Square cells for a structured look\n",
    "ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Significance Test Random(Filled Up) vs HTL\")\n",
    "plt.savefig(\"./img/minimal-difference/no_htl_vs_htl_vs_random.pdf\", format=\"pdf\", dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5580e9",
   "metadata": {},
   "source": [
    "### Marked Samples Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab6a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def collect_asset_paths(ASSET_PATHS: Optional[Path] = Path(\"cache\", \"assets\", COMET_WORKSPACE)) -> DefaultDict[str, List]:\n",
    "    TASK_ASSET_MAP = defaultdict(list)\n",
    "    for path in ASSET_PATHS.glob('**/*'):\n",
    "        if path.name.endswith(\"_Marked_Samples.npy\"):\n",
    "            task_name = path.parent.parent.name\n",
    "            if task_name != COMET_WORKSPACE:\n",
    "                TASK_ASSET_MAP[task_name].append(path)\n",
    "\n",
    "    return TASK_ASSET_MAP\n",
    "\n",
    "def load_asset_data(workspace_data: DefaultDict[str, List[Path]]) -> Dict[str, pd.DataFrame]:\n",
    "    results = {}\n",
    "    for task_name, assets in workspace_data.items():\n",
    "        collected_dfs = defaultdict(list)\n",
    "\n",
    "        for asset_path in assets:\n",
    "            data = np.load(asset_path)\n",
    "            if data.size == 0:\n",
    "                print(f\"{asset_path} is empty\")\n",
    "\n",
    "            filter_strategy_name = filter_names_clean[asset_path.name.replace(\"_Marked_Samples.npy\", \"\")]\n",
    "            collected_dfs[filter_strategy_name].append(data)\n",
    "\n",
    "\n",
    "        results[task_name] = pd.DataFrame(collected_dfs)\n",
    "    return results\n",
    "\n",
    "def group_by_filter_strategy(paths: List[Path]) -> DefaultDict[str, List[Path]]:\n",
    "    collected_dfs = defaultdict(list)\n",
    "    for asset_path in paths:\n",
    "        filter_strategy_name = filter_names_clean[asset_path.name.replace(\"_Marked_Samples.npy\", \"\")]\n",
    "        collected_dfs[filter_strategy_name].append(asset_path)\n",
    "\n",
    "    return collected_dfs\n",
    "\n",
    "def load_asset_data_for_coefficients(workspace_data: DefaultDict[str, List[Path]]) -> Dict[str, pd.DataFrame]:\n",
    "    results = {}\n",
    "    for task_name, assets in workspace_data.items():\n",
    "\n",
    "        collected_dfs = group_by_filter_strategy(assets)\n",
    "\n",
    "        tmp = []\n",
    "        for strategy, paths in collected_dfs.items():\n",
    "            seeds = []\n",
    "            seed_data = []\n",
    "            for path in sorted(paths):\n",
    "                data = np.load(path)\n",
    "                seed = int(path.parent.stem)\n",
    "\n",
    "                seeds.append(seed)\n",
    "                seed_data.append(data)\n",
    "\n",
    "            df = pd.DataFrame(data={strategy : seed_data}, index=seeds)\n",
    "\n",
    "            tmp.append(df)\n",
    "\n",
    "\n",
    "        results[task_name] = pd.concat(tmp, axis=1)\n",
    "    return results\n",
    "\n",
    "def check_for_null(df: pd.DataFrame, strategy1: str, strategy2: str) -> bool:\n",
    "    return pd.isnull(df.loc[strategy1, strategy2])\n",
    "\n",
    "def update_coefficient_value(df: pd.DataFrame, strategy1: str, strategy2: str, coefficient_index: float):\n",
    "        df.loc[strategy1, strategy2] = coefficient_index\n",
    "\n",
    "\n",
    "def calculate_jaccard(x1: np.ndarray, x2: np.ndarray) -> float:\n",
    "    intersection = np.intersect1d(x1, x2).size\n",
    "    union = np.union1d(x1, x2).size\n",
    "    return (intersection / union) if union > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_overlap(x1, x2):\n",
    "    intersection = np.intersect1d(x1, x2).size\n",
    "    min_set = min(x1.size, x2.size)\n",
    "    return (intersection / min_set) if min_set > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "def calculate_coefficient_matrix(asset_data: Dict[str, pd.DataFrame], coefficient: Callable[[np.ndarray, np.ndarray], float]) -> pd.DataFrame:\n",
    "\n",
    "    total_seeds = np.array([42 + i for i in range(0, seed_count)])\n",
    "    strategies = np.array(asset_data[next(iter(asset_data))].columns)\n",
    "    strategy_pairs = list(combinations(strategies, 2))\n",
    "\n",
    "    total_results = []\n",
    "    for task_name, df in asset_data.items():\n",
    "        df_index = np.array(df.index)\n",
    "        # task_results = []\n",
    "        diff = np.setdiff1d(total_seeds, df_index)\n",
    "        if diff.size > 0:\n",
    "            print(f\"For the task '{task_name}' in '{COMET_WORKSPACE}' are incomplete seed values, namely: {diff}\")\n",
    "\n",
    "        for index in df_index:\n",
    "            intermediate_results = pd.DataFrame(index=strategies, columns=strategies)\n",
    "            for strategy1, strategy2 in strategy_pairs:\n",
    "                coffiecient_index = coefficient(\n",
    "                    df.loc[index, strategy1],\n",
    "                    df.loc[index, strategy2]\n",
    "                )\n",
    "\n",
    "                update_coefficient_value(intermediate_results, strategy1, strategy2, coffiecient_index)\n",
    "                update_coefficient_value(intermediate_results, strategy2, strategy1, coffiecient_index)\n",
    "\n",
    "            np.fill_diagonal(intermediate_results.values, 1)\n",
    "            total_results.append(intermediate_results)\n",
    "        \n",
    "        # total_results.append(sum(task_results) / len(task_results))\n",
    "\n",
    "    overlap_matrix = sum(total_results) / len(total_results)\n",
    "    overlap_matrix = overlap_matrix.astype(float)\n",
    "    return overlap_matrix\n",
    "\n",
    "def plot_data(data: pd.DataFrame, coefficient_name: str):\n",
    "    # Set up the plot in stairwell style\n",
    "    sns.set_theme(style=\"white\")\n",
    "    colors = sns.color_palette(\"YlGnBu\", as_cmap=True)  # Stairwell-style color palette\n",
    "\n",
    "    # Plot the heatmap\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    sns.heatmap(\n",
    "        data=data,                     # Overlap matrix as data\n",
    "        cmap=colors,                   # Use stairwell style color map\n",
    "        annot=True,                    # Annotate cells with values\n",
    "        fmt=\".2f\",                     # Format annotations to 2 decimal places\n",
    "        annot_kws={\"size\": 8},         # Font size for annotations\n",
    "        linewidths=0.5,                # Thin borders for each cell\n",
    "        linecolor='grey',              # Grey borders to define the stairwell look\n",
    "        cbar_kws={'shrink': 0.5},      # Shrink color bar for fitting\n",
    "        square=True                    # Square cells for a structured look\n",
    "    )\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)   # Set spine visibility to True\n",
    "        spine.set_linewidth(0.75)    # Adjust border width\n",
    "        spine.set_color('grey')  # Set border color\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(f\"{coefficient_name} Coefficient Heatmap for Filter Strategies\", fontsize=12, pad=10)\n",
    "    plt.savefig(f\"./img/minimal-difference/{coefficient_name}.pdf\", format=\"pdf\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def jaccard_coefficient(asset_data: Dict[str, pd.DataFrame]):\n",
    "    overlap_matrix = calculate_coefficient_matrix(asset_data, calculate_jaccard)\n",
    "    plot_data(overlap_matrix, \"Jaccard\")\n",
    "\n",
    "def overlap_coefficient(asset_data: Dict[str, pd.DataFrame]):\n",
    "    overlap_matrix = calculate_coefficient_matrix(asset_data, calculate_overlap)\n",
    "    plot_data(overlap_matrix, \"Overlap\")\n",
    "\n",
    "\n",
    "def average_marked_samples() -> None:\n",
    "    workspace_data = collect_asset_paths()\n",
    "    marked_samples = load_asset_data(workspace_data=workspace_data)\n",
    "\n",
    "    dfs = []\n",
    "    for task_name, df in marked_samples.items():\n",
    "        collected_assets = {}\n",
    "        for col in df.columns:\n",
    "            avg_marked = np.concatenate(df[col].values).size / df[col].size\n",
    "            collected_assets[col] = avg_marked\n",
    "\n",
    "        asset_df = pd.DataFrame(data=collected_assets, index=[task_name])\n",
    "        dfs.append(asset_df)\n",
    "\n",
    "    merged_df = pd.concat(dfs)\n",
    "\n",
    "    sns.set_theme()\n",
    "    colors = sns.color_palette(\"YlGnBu\", as_cmap=True)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 7))\n",
    "\n",
    "    sns.heatmap(\n",
    "        data=merged_df,\n",
    "        cmap=colors,                   # Use stairwell style color map\n",
    "        annot=True,                    # Annotate cells with values\n",
    "        fmt=\".2f\",                     # Format annotations to 2 decimal places\n",
    "        annot_kws={\"size\": 12},         # Font size for annotations\n",
    "        linewidths=0.5,                # Thin borders for each cell\n",
    "        linecolor='black',              # Grey borders to define the stairwell look\n",
    "        cbar_kws={'shrink': 0.5},      # Shrink color bar for fitting\n",
    "    )\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)   # Set spine visibility to True\n",
    "        spine.set_linewidth(0.75)    # Adjust border width\n",
    "        spine.set_color('grey')  # Set border color\n",
    "\n",
    "    # Adjust the layout to make boxes fit better\n",
    "    # plt.tight_layout()\n",
    "    ax.set_title(f\"Average Marked Samples for each Filter Strategy over {seed_count} seeds.\", fontsize=12, pad=10)  # You can change the title, font size, and padding\n",
    "    plt.savefig(f\"./img/minimal-difference/Marked_Samples.pdf\", format=\"pdf\", dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "asset_paths = collect_asset_paths()\n",
    "loaded_assets = load_asset_data_for_coefficients(asset_paths)\n",
    "overlap_coefficient(loaded_assets)\n",
    "jaccard_coefficient(loaded_assets)\n",
    "average_marked_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a5e37b",
   "metadata": {},
   "source": [
    "### Final Experiment Visualisation (Over all Tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43463500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "filter_names_clean = {\n",
    "    \"SimpleDSM\": \"Simple DSM\",\n",
    "    \"SemanticAE\": \"Semantic AE\",\n",
    "    \"SimpleSS\": \"Simple SS\",\n",
    "    \"HDBScanFilter\": \"HDBScan\",\n",
    "    \"IsolationForestFilter\": \"IsolationForest\",\n",
    "    \"LocalOutlierFactorFilter\": \"LocalOutlierFactor\",\n",
    "}\n",
    "\n",
    "def load_asset_data_baseline(ASSET_PATHS: Optional[Path] = Path(\"cache\", \"assets\", COMET_WORKSPACE)) -> DefaultDict[str, List]:\n",
    "    TASK_ASSET_MAP = defaultdict(list)\n",
    "    for path in ASSET_PATHS.glob('**/*'):\n",
    "        if path.name.endswith(\"f1s.npy\"):\n",
    "            task_name = path.parent.parent.name\n",
    "            if task_name != COMET_WORKSPACE:\n",
    "                data = np.load(path)\n",
    "                if data.size == 0:\n",
    "                    print(f\"{path} is empty\")\n",
    "                TASK_ASSET_MAP[task_name].append(data)\n",
    "\n",
    "    return TASK_ASSET_MAP\n",
    "\n",
    "\n",
    "def collect_asset_paths(ASSET_PATHS: Optional[Path] = Path(\"cache\", \"assets\", COMET_WORKSPACE)) -> DefaultDict[str, List]:\n",
    "    TASK_ASSET_MAP = defaultdict(list)\n",
    "    for path in ASSET_PATHS.glob('**/*'):\n",
    "        if path.name.endswith(\"_f1s.npy\"):\n",
    "            task_name = path.parent.parent.name\n",
    "            if task_name != COMET_WORKSPACE:\n",
    "                TASK_ASSET_MAP[task_name].append(path)\n",
    "\n",
    "    return TASK_ASSET_MAP\n",
    "\n",
    "def load_asset_data(workspace_data: DefaultDict[str, List[Path]]) -> Dict[str, pd.DataFrame]:\n",
    "    results = {}\n",
    "    for task_name, assets in workspace_data.items():\n",
    "        collected_dfs = defaultdict(list)\n",
    "\n",
    "        for asset_path in assets:\n",
    "            data = np.load(asset_path)\n",
    "            if data.size == 0:\n",
    "                print(f\"{asset_path} is empty\")\n",
    "\n",
    "            filter_strategy_name = filter_names_clean[asset_path.name.replace(\"_f1s.npy\", \"\")]\n",
    "            collected_dfs[filter_strategy_name].append(data)\n",
    "\n",
    "\n",
    "        df = pd.DataFrame.from_dict(collected_dfs, orient=\"index\")\n",
    "        df = df.transpose()\n",
    "        results[task_name] = df\n",
    "    return results\n",
    "\n",
    "def transform_into_baseline(data, baseline_name: str):\n",
    "    df = pd.DataFrame.from_dict(data, orient=\"columns\")\n",
    "    df_transformed = df.apply(pd.Series.explode).reset_index(drop=True)\n",
    "    df_single_column = df_transformed.stack().reset_index(drop=True).to_frame(name=baseline_name)\n",
    "    return df_single_column\n",
    "\n",
    "def transform_into_experimental_data(data):\n",
    "    results = []\n",
    "    for df in data.values():\n",
    "        df_transformed = df.apply(pd.Series.explode).reset_index(drop=True)\n",
    "        results.append(df_transformed)\n",
    "\n",
    "    return pd.concat(results, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "def baseline() -> None:\n",
    "    random_baseline_data = load_asset_data_baseline(ASSET_PATHS=Path(\"cache\", \"assets\", \"final-experiment-random-sampling-all-filters\"))\n",
    "    prediction_entropy_uncertainty_data = load_asset_data_baseline(ASSET_PATHS=Path(\"cache\", \"assets\", \"final-experiment-prediction-entropy-no-filters\"))\n",
    "    prediction_entropy_data = load_asset_data_baseline(ASSET_PATHS=Path(\"cache\", \"assets\", \"final-experiment-no-filters\"))\n",
    "    actual_experiments = load_asset_data(collect_asset_paths(ASSET_PATHS= Path(\"cache\", \"assets\", \"final-experiment-all-filters\")))\n",
    "\n",
    "    random_base = transform_into_baseline(random_baseline_data, \"Random Sampling\")\n",
    "    uncertainty_base = transform_into_baseline(prediction_entropy_uncertainty_data, \"Prediction Entropy Uncertainty Clipped\")\n",
    "    entropy_base = transform_into_baseline(prediction_entropy_data, \"Prediction Entropy\")\n",
    "    experimental_data = transform_into_experimental_data(actual_experiments)\n",
    "\n",
    "    dfs_combined = pd.concat([random_base, uncertainty_base, entropy_base, experimental_data], axis=1)\n",
    "    dfs_long = dfs_combined.reset_index().melt(id_vars='index', var_name='Category', value_name='F1-Scores')\n",
    "    category_order = (\n",
    "        dfs_long.groupby('Category')['F1-Scores'].mean().sort_values(ascending=False).index.tolist()\n",
    "    )\n",
    "    sns.set_theme()\n",
    "    custom_palette = sns.color_palette(\"tab20\")\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.boxplot(data=dfs_long, x=\"Category\", y=\"F1-Scores\", palette=custom_palette, showmeans=True, order=category_order, width=0.2, gap=0.0, meanprops={\"marker\":\"d\",\"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\"})\n",
    "\n",
    "    # Hides the x-axis labels\n",
    "    plt.xticks(ticks=[], labels=[])\n",
    "    plt.yticks(np.arange(0.35, 1.05, step=0.05))\n",
    "\n",
    "    legend_patches = [\n",
    "        Patch(facecolor=custom_palette[i], edgecolor='black', label=category)\n",
    "        for i, category in enumerate(category_order)\n",
    "    ]\n",
    "\n",
    "    # Add the custom legend\n",
    "    plt.legend(\n",
    "        handles=legend_patches,\n",
    "        title=\"Categories\",\n",
    "        bbox_to_anchor=(1.05, 1),  # Position legend outside the plot\n",
    "        loc='upper left'\n",
    "    )\n",
    "\n",
    "    plt.title(\"Baseline Boxplots for Random, Prediction Entropy Uncertainty Clipped & Prediction Entropy\", fontsize=13)\n",
    "    plt.xlabel(\"Filter Strategy\", fontsize=11)\n",
    "    plt.ylabel(\"F1-Scores\", fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./img/final-experiment/boxplot-mean-descending-order.pdf\", format=\"pdf\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def end_performance_comparison() -> None:\n",
    "    workspace_data = collect_asset_paths()\n",
    "    f1_scores_map = load_asset_data(workspace_data=workspace_data)\n",
    "\n",
    "    dfs = []\n",
    "    for task_name, df in f1_scores_map.items():\n",
    "        collected_assets = {}\n",
    "        for col in df.columns:\n",
    "            values = df[col].values\n",
    "            df_summarised = np.concatenate([array_with_values if array_with_values is not None else np.array([]) for array_with_values in values])\n",
    "            collected_assets[col] = df_summarised\n",
    "\n",
    "\n",
    "        asset_df = pd.DataFrame(data=[collected_assets], index=[task_name])\n",
    "        dfs.append(asset_df)\n",
    "\n",
    "    merged_df = pd.concat(dfs)\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        col: [np.concatenate(merged_df[col].values)]  # Concatenate all arrays in each column\n",
    "        for col in merged_df.columns\n",
    "    })\n",
    "\n",
    "    sns.set_theme()\n",
    "\n",
    "    # Create the boxplot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(\n",
    "        data=summary,\n",
    "        showmeans=True\n",
    "        )\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# end_performance_comparison()\n",
    "baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a661a218",
   "metadata": {},
   "source": [
    "### Final Experiment Separated by Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "filter_names_clean = {\n",
    "    \"SimpleDSM\": \"Simple DSM\",\n",
    "    \"SemanticAE\": \"Semantic AE\",\n",
    "    \"SimpleSS\": \"Simple SS\",\n",
    "    \"HDBScanFilter\": \"HDBScan\",\n",
    "    \"IsolationForestFilter\": \"IsolationForest\",\n",
    "    \"LocalOutlierFactorFilter\": \"LocalOutlierFactor\",\n",
    "}\n",
    "\n",
    "def load_asset_data_baseline(ASSET_PATHS: Optional[Path] = Path(\"cache\", \"assets\", COMET_WORKSPACE)) -> DefaultDict[str, List]:\n",
    "    TASK_ASSET_MAP = defaultdict(list)\n",
    "    for path in ASSET_PATHS.glob('**/*'):\n",
    "        if path.name.endswith(\"f1s.npy\"):\n",
    "            task_name = path.parent.parent.name\n",
    "            if task_name != COMET_WORKSPACE:\n",
    "                data = np.load(path)\n",
    "                if data.size == 0:\n",
    "                    print(f\"{path} is empty\")\n",
    "                TASK_ASSET_MAP[task_name].append(data)\n",
    "\n",
    "    return TASK_ASSET_MAP\n",
    "\n",
    "\n",
    "def collect_asset_paths(ASSET_PATHS: Optional[Path] = Path(\"cache\", \"assets\", COMET_WORKSPACE)) -> DefaultDict[str, List]:\n",
    "    TASK_ASSET_MAP = defaultdict(list)\n",
    "    for path in ASSET_PATHS.glob('**/*'):\n",
    "        if path.name.endswith(\"_f1s.npy\"):\n",
    "            task_name = path.parent.parent.name\n",
    "            if task_name != COMET_WORKSPACE:\n",
    "                TASK_ASSET_MAP[task_name].append(path)\n",
    "\n",
    "    return TASK_ASSET_MAP\n",
    "\n",
    "def load_asset_data(workspace_data: DefaultDict[str, List[Path]]) -> Dict[str, pd.DataFrame]:\n",
    "    results = {}\n",
    "    for task_name, assets in workspace_data.items():\n",
    "        collected_dfs = defaultdict(list)\n",
    "\n",
    "        for asset_path in assets:\n",
    "            data: np.ndarray = np.load(asset_path)\n",
    "            if data.size == 0:\n",
    "                print(f\"{asset_path} is empty\")\n",
    "\n",
    "            filter_strategy_name = filter_names_clean[asset_path.name.replace(\"_f1s.npy\", \"\")]\n",
    "            collected_dfs[filter_strategy_name].append(data)\n",
    "\n",
    "\n",
    "        df = pd.DataFrame.from_dict(collected_dfs, orient=\"index\")\n",
    "        df = df.transpose()\n",
    "        results[task_name] = df\n",
    "    return results\n",
    "\n",
    "\n",
    "def transform_into_experimental_data(data):\n",
    "    results = []\n",
    "    for df in data.values():\n",
    "        df_transformed = df.apply(pd.Series.explode).reset_index(drop=True)\n",
    "        results.append(df_transformed)\n",
    "\n",
    "    return pd.concat(results, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "def baseline() -> None:\n",
    "    random_baseline_data = load_asset_data_baseline(ASSET_PATHS=Path(\"cache\", \"assets\", \"final-experiment-random-sampling-all-filters\"))\n",
    "    prediction_entropy_uncertainty_data = load_asset_data_baseline(ASSET_PATHS=Path(\"cache\", \"assets\", \"final-experiment-prediction-entropy-no-filters\"))\n",
    "    prediction_entropy_data = load_asset_data_baseline(ASSET_PATHS=Path(\"cache\", \"assets\", \"final-experiment-no-filters\"))\n",
    "    actual_experiments = load_asset_data(collect_asset_paths(ASSET_PATHS= Path(\"cache\", \"assets\", \"final-experiment-all-filters\")))\n",
    "\n",
    "    for task, df in actual_experiments.items():\n",
    "        df[\"Random Sampling\"] = random_baseline_data[task]\n",
    "        df[\"Prediction Entropy Uncertainty Clipped\"] = prediction_entropy_uncertainty_data[task]\n",
    "        df[\"Prediction Entropy\"] = prediction_entropy_data[task]\n",
    "\n",
    "        df_transformed = df.apply(pd.Series.explode).reset_index(drop=True)\n",
    "\n",
    "        category_order = df_transformed.mean().sort_values(ascending=False).index.tolist()\n",
    "        df_ordered_by_mean = df_transformed[category_order]\n",
    "        sns.set_theme()\n",
    "        custom_palette = sns.color_palette(\"tab20\")\n",
    "\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        sns.boxplot(data=df_ordered_by_mean, palette=custom_palette, showmeans=True, order=category_order, width=0.4, gap=0.0, meanprops={\"marker\":\"d\",\"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\"})\n",
    "\n",
    "        min_tick = df_ordered_by_mean.min().min()\n",
    "        # Hides the x-axis labels\n",
    "        plt.xticks(ticks=[], labels=[])\n",
    "        plt.yticks(np.arange(np.floor(min_tick * 10) / 10 - 0.05, 1.0, step=0.05))\n",
    "\n",
    "        legend_patches = [\n",
    "            Patch(facecolor=custom_palette[i], edgecolor='black', label=category)\n",
    "            for i, category in enumerate(category_order)\n",
    "        ]\n",
    "\n",
    "        # Add the custom legend\n",
    "        plt.legend(\n",
    "            handles=legend_patches,\n",
    "            title=\"Categories\",\n",
    "            bbox_to_anchor=(1.05, 1),  # Position legend outside the plot\n",
    "            loc='upper left'\n",
    "        )\n",
    "\n",
    "        plt.title(\"Baseline Boxplots for Random, Prediction Entropy Uncertainty Clipped & Prediction Entropy\", fontsize=13)\n",
    "        plt.xlabel(f\"Filter Strategy for {task}\", fontsize=11)\n",
    "        plt.ylabel(\"F1-Scores\", fontsize=11)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"./img/final-experiment/{task}-boxplot-mean-of-mean-descending-order.pdf\", format=\"pdf\", dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b02506",
   "metadata": {},
   "source": [
    "### Final Experiment Ranked by Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "filter_names_clean = {\n",
    "    \"SimpleDSM\": \"Simple DSM\",\n",
    "    \"SemanticAE\": \"Semantic AE\",\n",
    "    \"SimpleSS\": \"Simple SS\",\n",
    "    \"HDBScanFilter\": \"HDBScan\",\n",
    "    \"IsolationForestFilter\": \"IsolationForest\",\n",
    "    \"LocalOutlierFactorFilter\": \"LocalOutlierFactor\",\n",
    "}\n",
    "\n",
    "def load_asset_data_baseline(ASSET_PATHS: Optional[Path] = Path(\"cache\", \"assets\", COMET_WORKSPACE)) -> DefaultDict[str, List]:\n",
    "    TASK_ASSET_MAP = defaultdict(list)\n",
    "    for path in ASSET_PATHS.glob('**/*'):\n",
    "        if path.name.endswith(\"f1s.npy\"):\n",
    "            task_name = path.parent.parent.name\n",
    "            if task_name != COMET_WORKSPACE:\n",
    "                data = np.load(path)\n",
    "                if data.size == 0:\n",
    "                    print(f\"{path} is empty\")\n",
    "                TASK_ASSET_MAP[task_name].append(data.mean())\n",
    "\n",
    "    return TASK_ASSET_MAP\n",
    "\n",
    "\n",
    "def collect_asset_paths(ASSET_PATHS: Optional[Path] = Path(\"cache\", \"assets\", COMET_WORKSPACE)) -> DefaultDict[str, List]:\n",
    "    TASK_ASSET_MAP = defaultdict(list)\n",
    "    for path in ASSET_PATHS.glob('**/*'):\n",
    "        if path.name.endswith(\"_f1s.npy\"):\n",
    "            task_name = path.parent.parent.name\n",
    "            if task_name != COMET_WORKSPACE:\n",
    "                TASK_ASSET_MAP[task_name].append(path)\n",
    "\n",
    "    return TASK_ASSET_MAP\n",
    "\n",
    "def load_asset_data(workspace_data: DefaultDict[str, List[Path]]) -> Dict[str, pd.DataFrame]:\n",
    "    results = {}\n",
    "    for task_name, assets in workspace_data.items():\n",
    "        collected_dfs = defaultdict(list)\n",
    "\n",
    "        for asset_path in assets:\n",
    "            data: np.ndarray = np.load(asset_path)\n",
    "            if data.size == 0:\n",
    "                print(f\"{asset_path} is empty\")\n",
    "\n",
    "            filter_strategy_name = filter_names_clean[asset_path.name.replace(\"_f1s.npy\", \"\")]\n",
    "            collected_dfs[filter_strategy_name].append(data.mean())\n",
    "\n",
    "        df = pd.DataFrame.from_dict(collected_dfs, orient=\"index\")\n",
    "        df = df.transpose()\n",
    "        results[task_name] = df\n",
    "    return results\n",
    "\n",
    "\n",
    "def transform_into_experimental_data(data):\n",
    "    results = []\n",
    "    for df in data.values():\n",
    "        df_transformed = df.apply(pd.Series.explode).reset_index(drop=True)\n",
    "        results.append(df_transformed)\n",
    "\n",
    "    return pd.concat(results, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "def baseline() -> None:\n",
    "    random_baseline_data = load_asset_data_baseline(ASSET_PATHS=Path(\"cache\", \"assets\", \"final-experiment-random-sampling-all-filters\"))\n",
    "    prediction_entropy_uncertainty_data = load_asset_data_baseline(ASSET_PATHS=Path(\"cache\", \"assets\", \"final-experiment-prediction-entropy-no-filters\"))\n",
    "    prediction_entropy_data = load_asset_data_baseline(ASSET_PATHS=Path(\"cache\", \"assets\", \"final-experiment-no-filters\"))\n",
    "    actual_experiments = load_asset_data(collect_asset_paths(ASSET_PATHS= Path(\"cache\", \"assets\", \"final-experiment-all-filters\")))\n",
    "\n",
    "    categories_ranking = {\n",
    "        \"Random Sampling\" : [],\n",
    "        \"Prediction Entropy Uncertainty Clipped\" : [],\n",
    "        \"Prediction Entropy\" : [],\n",
    "        \"Simple DSM\": [],\n",
    "        \"Semantic AE\": [],\n",
    "        \"Simple SS\": [],\n",
    "        \"HDBScan\": [],\n",
    "        \"IsolationForest\": [],\n",
    "        \"LocalOutlierFactor\": [],\n",
    "        }\n",
    "\n",
    "    for task, df in actual_experiments.items():\n",
    "        df[\"Random Sampling\"] = random_baseline_data[task]\n",
    "        df[\"Prediction Entropy Uncertainty Clipped\"] = prediction_entropy_uncertainty_data[task]\n",
    "        df[\"Prediction Entropy\"] = prediction_entropy_data[task]\n",
    "\n",
    "        df_transformed = df.apply(pd.Series.explode).reset_index(drop=True)\n",
    "        category_order = df_transformed.mean().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "        for category in categories_ranking.keys():\n",
    "            categories_ranking[category].append(category_order.index(category) + 1)\n",
    "\n",
    "    results = {}\n",
    "    for category, rankings in categories_ranking.items():\n",
    "        results[category] = sum(rankings) / len(actual_experiments.keys())\n",
    "\n",
    "    ranking_df = pd.DataFrame.from_dict(data=[results])\n",
    "    ranking_df.index = [\"Ranking\"]\n",
    "\n",
    "\n",
    "    sns.set_theme()\n",
    "    custom_palette = sns.color_palette(\"tab20\")\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.barplot(data=ranking_df, palette=custom_palette, width=0.4, gap=0.0)\n",
    "\n",
    "    # Hides the x-axis labels\n",
    "    plt.xticks(ticks=[], labels=[])\n",
    "\n",
    "    legend_patches = [\n",
    "        Patch(facecolor=custom_palette[i], edgecolor='black', label=category)\n",
    "        for i, category in enumerate(category_order)\n",
    "    ]\n",
    "\n",
    "    # Add the custom legend\n",
    "    plt.legend(\n",
    "        handles=legend_patches,\n",
    "        title=\"Categories\",\n",
    "        bbox_to_anchor=(1.05, 1),  # Position legend outside the plot\n",
    "        loc='upper left'\n",
    "    )\n",
    "\n",
    "    plt.title(\"Baseline Boxplots for Random, Prediction Entropy Uncertainty Clipped & Prediction Entropy\", fontsize=13)\n",
    "    plt.xlabel(f\"Strategies\", fontsize=11)\n",
    "    plt.ylabel(\"Ranked by F1-Score Performance\", fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./img/final-experiment/rank-order-boxplot-descending.pdf\", format=\"pdf\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e904a",
   "metadata": {},
   "source": [
    "### Percentiles Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44510d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_asset_data_baseline(ASSET_PATHS: Optional[Path] = Path(\"cache\", \"assets\", COMET_WORKSPACE)) -> DefaultDict[str, List]:\n",
    "    TASK_ASSET_MAP = defaultdict(list)\n",
    "    for path in ASSET_PATHS.glob('**/*'):\n",
    "        if path.name.endswith(\"f1s.npy\"):\n",
    "            task_name = path.parent.parent.name\n",
    "            if task_name != COMET_WORKSPACE:\n",
    "                data = np.load(path)\n",
    "                if data.size == 0:\n",
    "                    print(f\"{path} is empty\")\n",
    "                TASK_ASSET_MAP[task_name].append(data)\n",
    "\n",
    "    return TASK_ASSET_MAP\n",
    "\n",
    "\n",
    "def collect_asset_paths(ASSET_PATHS: Optional[Path] = Path(\"cache\", \"assets\", COMET_WORKSPACE)) -> DefaultDict[str, List]:\n",
    "    TASK_ASSET_MAP = defaultdict(list)\n",
    "    for path in ASSET_PATHS.glob('**/*'):\n",
    "        if path.name.endswith(\"_f1s.npy\"):\n",
    "            task_name = path.parent.parent.name\n",
    "            if task_name != COMET_WORKSPACE:\n",
    "                TASK_ASSET_MAP[task_name].append(path)\n",
    "\n",
    "    return TASK_ASSET_MAP\n",
    "\n",
    "def load_asset_data(workspace_data: DefaultDict[str, List[Path]]) -> Dict[str, pd.DataFrame]:\n",
    "    results = {}\n",
    "    for task_name, assets in workspace_data.items():\n",
    "        collected_dfs = defaultdict(list)\n",
    "\n",
    "        for asset_path in assets:\n",
    "            data = np.load(asset_path)\n",
    "            if data.size == 0:\n",
    "                print(f\"{asset_path} is empty\")\n",
    "\n",
    "            filter_strategy_name = filter_names_clean[asset_path.name.replace(\"_f1s.npy\", \"\")]\n",
    "            collected_dfs[filter_strategy_name].append(data)\n",
    "\n",
    "\n",
    "        df = pd.DataFrame.from_dict(collected_dfs, orient=\"index\")\n",
    "        df = df.transpose()\n",
    "        results[task_name] = df\n",
    "    return results\n",
    "\n",
    "def transform_into_baseline(data, workspace_name):\n",
    "    df = pd.DataFrame.from_dict(data, orient=\"columns\")\n",
    "    df_transformed = df.apply(pd.Series.explode).reset_index(drop=True)\n",
    "    df_mean = df_transformed.mean(axis=0)\n",
    "    result_df = pd.DataFrame({workspace_name : df_mean.values}, index=[df_mean.index])\n",
    "    return result_df\n",
    "\n",
    "def prepare_percentiles_data():\n",
    "    workspaces = [\"final-20-percentile-adjusted\",\"final-experiment-20-percentile\",\"final-experiment-30-percentile\",\"final-experiment-40-percentile\",\"final-experiment-85-percentile\",\"final-experiment-90-percentile\", \"final-experiment-95-percentile\", \"final-experiment-99-percentile\"]\n",
    "    results = [load_asset_data_baseline(ASSET_PATHS=Path(\"cache\", \"assets\", workspace)) for workspace in workspaces]\n",
    "    x = pd.concat([transform_into_baseline(data, workspaces[index]) for index, data in enumerate(results, start=0)], axis=1)\n",
    "    x.to_csv(\"./img/percentiles/percentiles_mean.csv\", index=True)\n",
    "    return x\n",
    "\n",
    "prepare_percentiles_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6922f7",
   "metadata": {},
   "source": [
    "### Optional Code Segment to move files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e15d1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_ASSET_MAP = defaultdict(list)\n",
    "for path in Path(\"cache\", \"assets\", \"sklearn-20-5\").glob('**/*'):\n",
    "    if path.name.endswith(\".npy\") and not path.name == \"HTL.npy\":\n",
    "        seed = path.parent.stem\n",
    "        task_name = path.parent.parent.name\n",
    "        # print(Path(\"cache\", \"assets\", \"outlier-detection\", task_name, seed, path.name))\n",
    "        path.rename(Path(\"cache\", \"assets\", \"outlier-detection\", task_name, seed, path.name))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenseoracle-84WfDBL7-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
